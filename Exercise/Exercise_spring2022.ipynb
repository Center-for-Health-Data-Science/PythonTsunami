{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3YLOMOoHRwRR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9Nxy_ic9GgE"
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Now that we have learned some of the basics of python, we should practice how to use this new superpower. We have here prepared a loosely guided exercise that focusses on data exploration and visualization on two example datasets, one on strokes and one on cirrhosis. You can also explore a dataset of your choosing, though the questions are prepared with the example datasets in mind.\n",
    "\n",
    "Here you can see the [metadata](https://www.kaggle.com/datasets/fedesoriano/cirrhosis-prediction-dataset) for the cirrhosis dataset which describes what each of the columns are. For the stroke data the meaning of the columns is more straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVWSFVPK9TCe"
   },
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "We will start with the stroke dataset. You can find it on the GitHub repository under Exercise/datasets.\n",
    "\n",
    "1. Load the stroke data into colab by using one of the two approaches detailed below and assign it to variable name ```data```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SmuuZeHpx3S_"
   },
   "source": [
    "### 1.1 Loading the data\n",
    "\n",
    "**Option 1:**\n",
    "\n",
    "Use the pandas csv reader with a link to the data on GitHub. To do this, go to the github repository, find the stroke dataset and click on the 'raw' button. Copy that link and enter it as the file path in pandas csv reader.\n",
    "\n",
    "Import via Github link: Go to the github repository, find the dataset you want to work with and click on the 'raw' button. Copy the link and enter it as the file directory in pandas csv reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lGW4Cz2AsojD",
    "outputId": "d116586d-b178-4b68-9e43-33b621615050"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "id": "vR5EptJg0G1J",
    "outputId": "36b6ab74-9760-45b7-8ada-672b6902d1a4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXMXD20CxXHT"
   },
   "source": [
    "... or\n",
    "\n",
    "**Option 2**\n",
    "\n",
    "Manually load the dataset into colab and then read it with the pandas csv reader. See steps below:\n",
    "\n",
    "1. go to the left side bar and click on the folder icon\n",
    "2. click on data upload\n",
    "3. select dataset from your computer\n",
    "4. call pandas csv reader with the name of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWfDOeGB9Uw2",
    "outputId": "23cec57b-61fe-4434-ec7b-7f9078c3d7db"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gf5b1jRGxVOO"
   },
   "source": [
    "### 1.2 First look\n",
    "\n",
    "2. Have a first look at the data. There are some neat built-in pandas functions to get an initial understanding of the data. \n",
    "\n",
    "Questions you might want to answer here: \n",
    "- What different types of columns do you have? \n",
    "- Is there a column that describes an 'outcome' ? \n",
    "- How many values does each feature, i.e. column, have and what are some preliminary statistics of the features? (tip: use pandas `describe` function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JVMoOn5G9bMp",
    "outputId": "3c434a9b-c6c1-4f16-e154-dc526e61ec94"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-U3eWqWn9fCX",
    "outputId": "bdcd5a2d-5b76-4997-b269-4415f85f3801"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It helps to know which column is the outcome variable. In the stroke datasets (and many others!) the outcome variable is coded as a numerical variable. However, during analysis it should be interpreted as categorical. \n",
    "\n",
    "Identify the column of the outcome variable and change its type to \"object\". \n",
    "Use `describe()` on the dataframe again. Has it changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ScZ9eNl99zEN"
   },
   "source": [
    "## 2. Exploratory analysis\n",
    "\n",
    "Get to know your data better. If you want to first visually inspect the data it can help to explore with some plots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Violin plots and histograms\n",
    "\n",
    "Consider you dataframe columns that are not the outcome. How are the measurements distributed? \n",
    "\n",
    "We want to make **violin plots** of variables, i.e. data columns, that are numeric and **histrograms** of the variables that are strings/ categorical. We also want to add these plots to a list of plots.\n",
    "\n",
    "Try to divide this task up into subtasks:\n",
    "\n",
    "0. Initiate an empty list\n",
    "1. Find out how to go through all columns except the outcome\n",
    "2. Check the datatype of each column\n",
    "3. Make a violin plot or histogram \n",
    "4. Add the plot to the list\n",
    "\n",
    "\n",
    "In the end you can wrap you code into a function that takes the dataframe and the name of the outcome variable as inputs and returns a list of plots.\n",
    "\n",
    "**Pro version**: Some columns are not actually predictors, such as a the ID column. You can identify these columns i.e. by seeing that each of their values is unique (this would be very unlikely for a measured variable). Skip them when making the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "llINtmry-NqA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-d-4HSAay-xc"
   },
   "source": [
    "### 2.2 Correlation coefficients\n",
    "\n",
    "Plot the correlation coefficients of all numerical features:\n",
    "\n",
    "1. Use the method `corr()` on the dataframe. What is the result?\n",
    "\n",
    "2. Now use a heatmap to show the correlation coeffcients graphically.\n",
    "\n",
    "3. Try some different options to make your heatmap look nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "yc3GuLRe-U6l",
    "outputId": "b70f3805-16ae-473e-98e3-1d6035897577"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9Ez8XDCzCGW"
   },
   "source": [
    "### 2.3 Scatter plot\n",
    "\n",
    "Make a scatter plot of the two variables with the highest correlation. Divide the plots by the outcome variable and add marginal plots and a trendline:\n",
    "\n",
    "1. Find the pair of variables that has the highest correlation with each other and make a scatter plot of them. \n",
    "\n",
    "2. Divide the scatter plot into two by the outcome variable. Have a look at ``facet`` and the visualization lecture if you have trouble. \n",
    "\n",
    "3. Add marginal distributions and a trendline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "5xNHY4LwAJx8",
    "outputId": "ff56127e-c7fd-4370-d5af-525c6f2d58eb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XzWC3UdNAhdt"
   },
   "source": [
    "## 3. Data cleaning\n",
    "\n",
    "Now, we switch the [cirrhosis dataset]('https://raw.githubusercontent.com/Center-for-Health-Data-Science/PythonTsunami/spring2022/Exercise/datasets/cirrhosis.csv').\n",
    "\n",
    "We will investigate what data is missing and try to impute it.\n",
    "\n",
    "A word of caution:\n",
    "\n",
    "Note that imputation is a __complex subject__ and whether it makes sense to do it and the method used highly depend on the data set. Sometimes, the mean of a value across all non-missing observations is a good approximation for the missing value. On the other hand, if you have a column that says whether or not the person was treated with the drug or the placebo we have no good way to guess which treatment the person received. Replacing missing values in this column with the most common value (which is that they did get the drug) will produce extremely __wrong data__ and lead you to __wrong conclusions__. Do not do that!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Load the data\n",
    "\n",
    "Load in the cirrhosis dataset using one of the two methods you used earlier for the stroke data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Missing data\n",
    "\n",
    "1. Use the pandas method `isnull`. Which features, i.e. columns have missing values? \n",
    "\n",
    "2. Get the number of missing values per column by calling `sum()` on the result of `isnull`.\n",
    "\n",
    "3. Make a barplot that shows the number of missing values per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KB_RPg-U9i8J",
    "outputId": "0e8b746c-6a6e-45f8-9e17-ee1f695487a3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 676
    },
    "id": "XEbMbPHqAj2X",
    "outputId": "78a35ec2-c230-4859-9dea-19e713af43df"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qBOePAlzIrv"
   },
   "source": [
    "### 3.2 Omitting observations with missing values\n",
    "\n",
    "1. Create a subset in which you omit all patients, i.e. rows, which have missing values in any column. Take care to not overwrite the original dataframe. If you did, you can re-import it. \n",
    "\n",
    "2. How many observations, i.e. patients, would you be left with if you removed all missing values?\n",
    "\n",
    "3. How many if you only omit patients where the outcome is missing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j3rEUU7iA1La",
    "outputId": "6e30e79b-b57c-4bac-fab9-3f16e886435d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0SbRFgmGChph",
    "outputId": "1e978688-250b-4cdf-9731-cbb398c5f0f3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKknLSw1zOqi"
   },
   "source": [
    "### 3.3 Effects of removing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1_fL5hEC2LN"
   },
   "source": [
    "We can now have a look at how removing nans effects the data.\n",
    "\n",
    "\n",
    "1. First, plot the correlation coefficient between all numerical columns in the original cirrhosis dataframe. (Analogous to 2.2).\n",
    "\n",
    "2. Now, remake the plot for the subset where you have removed all rows with any missing data. Have the correlations changed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "id": "r5G9AqzzDSBJ",
    "outputId": "4ceb80f2-e439-4235-b732-430f63941f68"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9b40PElUzT-2"
   },
   "source": [
    "### 3.4 Imputation\n",
    "\n",
    "Use the method `fillna()` to impute missing values in the columns **where it makes sense**. Have a look at the documentation: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html\n",
    "\n",
    "1. A good way to impute numerical data can be i.e. the mean or median. Calculate the mean for all numerical columns. \n",
    "\n",
    "2. Make violin plots for all numerical columns, analogous to 2.1. Compare them to the means you calculated. Choose either the mean or median as the replacement for NaN in each numerical column.\n",
    "\n",
    "3. Perform the imputation.\n",
    "\n",
    "4. Re-make the barplot from 3.1. to check that it worked.\n",
    "\n",
    "5. Recalculate correlation coefficients between all numerical columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SF8PoOvOcp7n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Hto297viwyzY",
    "Gf5b1jRGxVOO",
    "TC6ewdf5qFze",
    "-d-4HSAay-xc",
    "v9Ez8XDCzCGW",
    "FxHy9gKJqtNE",
    "3qBOePAlzIrv",
    "nKknLSw1zOqi",
    "9b40PElUzT-2",
    "_CwrlBmMOzif",
    "ATnfchJIyGKj",
    "SS-KMKN7zeNw",
    "feYvDsddzhUl",
    "f8vhdvqVzjXi"
   ],
   "name": "Exercise_spring2022.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
