{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../figures/HeaDS_logo_large_withTitle.png\" width=\"300\">\n",
    "\n",
    "<img src=\"../figures/tsunami_logo.PNG\" width=\"600\">\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Center-for-Health-Data-Science/PythonTsunami/blob/fall2021/Pandas/Pandas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For (anonymous) questions**, use this **[Padlet link](https://ucph.padlet.org/henrikezschach1/7f65ytua2sv0qt9g)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas\n",
    "\n",
    "[Pandas cheat sheet](https://github.com/Center-for-Health-Data-Science/PythonTsunami/blob/fall2021/cheat_sheets/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Popular package for data science: offers powerful data structures that make data manipulation and analysis easy.\n",
    "\n",
    "The **`DataFrame`** is one of them.\n",
    "\n",
    "Pandas is built on top of `numpy`.\n",
    "\n",
    "Pandas is well suited for tabular data with heterogeneously-typed columns, as in an Excel spreadsheet\n",
    "\n",
    "Has an interface to directly plot using `maptlotlib`, `seaborn`, `plotly`, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two main classes (types/ objects)\n",
    "\n",
    "1. `pandas.Series`\n",
    "2. `pandas.DataFrame`\n",
    "\n",
    "- a `Series` is a `numpy.array` with an `Index` series.\n",
    "- a column in a `DataFrame` is a `Series`.\n",
    "- columns in a `DataFrame` share an `Index`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating an instance of a `pandas.Series`\n",
    "\n",
    "There are many ways. E.g from a list, a built-in `range` and `numpy` arrays.\n",
    "\n",
    "But a Series is an object holding some data.\n",
    "\n",
    "Let's create a Series from a list and a built-in `range`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list = pd.Series([3, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    "series_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "series_range = pd.Series(range(3, 13))\n",
    "series_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Series from list, underlying data:\\t\", series_list.values)\n",
    "print(\"Series from range, underlying data:\\t\", series_range.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_list.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "series_range.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "### Difference: indexing of data\n",
    "\n",
    "- pandas names \"data\" by an row indices (and column indices for 2D structures)\n",
    "- see also recent [talk on PyData2021](https://www.youtube.com/watch?v=oazUQPrs8nw) by James Powell (it's relatively fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "series1 = pd.Series([1,2,3], index=['row1', 'row2', 'row3'])\n",
    "series1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series2 = pd.Series([1,2,4])\n",
    "series2.index = ['row1', 'row2', 'row4']\n",
    "series2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "series1 + series2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A DataFrame is basically, a **Table** of data (or a tabular data structure) with labeled rows and columns. The rows are labeled by a special data structure called an Index, that permits fast look-up and powerful relational operations.\n",
    "\n",
    "![alt text](../figures/pandas_dataframe.png \"Title\")\n",
    "\n",
    "<div style=\"text-align: right\"> From https://www.geeksforgeeks.org/ </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create a DataFrame directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### From a `list` of `list`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    [2.23, 1, \"test\"],\n",
    "    [3.45, 2, \"train\"],\n",
    "    [4.5, 3, \"test\"],\n",
    "    [6.0, 4, \"train\"]\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### From a `list` of `dict`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'A': 2.23, 'B': 1, 'C': \"test\"},\n",
    "    {'A': 3.45, 'B': 2, 'C': \"train\"},\n",
    "    {'A': 4.5, 'B': 3, 'C': \"test\"},\n",
    "    {'A': 6.0, 'B': 4, 'C': \"train\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### From a Dict of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"A\": [2.23, 3.45, 4.5, 6.0],\n",
    "    \"B\": [1, 2, 3, 4],\n",
    "    \"C\": [\"test\", \"train\", \"test\", \"train\"],\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### From a `dict` of `dict`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"row1\": {\"A\": 2.23, \"B\": 1, \"C\": \"test\"},\n",
    "    \"row3\": {\"A\": 3.45, \"B\": 2, \"C\": \"train\"},\n",
    "    \"row2\": {\"A\": 4.5, \"B\": 3, \"C\": \"test\"},\n",
    "    \"row4\": {\"A\": 6.0, \"B\": 4, \"C\": \"train\"},\n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(\n",
    "    data,\n",
    "    orient=\"index\",  # default is columns. pd.DataFrame also works, but you have to transpose the data\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### From an empty `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['A'] = [2.23, 3.45, 4.5, 6.0]\n",
    "df['B'] = [1, 2, 3, 4]\n",
    "df['C'] = [\"test\", \"train\", \"test\", \"train\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    [2.23, 1, \"test\"],\n",
    "    [3.45, 2, \"train\"],\n",
    "    [4.5, 3, \"test\"],\n",
    "    [6.0, 4, \"train\"]\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, index=['row1', 'row2', 'row3', 'row4'], columns=['A', 'B', 'C'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = ['a', 'b', 'c', 'd']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 1\n",
    "Please recreate the table below as a Dataframe using one of the approaches detailed above:\n",
    "\n",
    "|  | Year | Product | Cost |\n",
    "| ---| :--: | :----:  | :--: |\n",
    "| 0  | 2015 | Apples  | 0.35 |\n",
    "| 1  | 2016 | Apples  | 0.45 |\n",
    "| 2  | 2015 | Bananas | 0.75 |\n",
    "| 3  | 2016 | Bananas | 1.10 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which approach did you prefer? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading data into `DataFrame`s from a file\n",
    "\n",
    "Pandas has functions that can make DataFrames from a wide variety of file types.  To do this, use one of the functions in Pandas that start with `read_`.  Here is a non-exclusive list of examples:\n",
    "\n",
    "| File Type | Function Name |\n",
    "| :----:    |  :---:  |\n",
    "| Excel | `pd.read_excel` |\n",
    "| CSV, TSV | `pd.read_csv` |\n",
    "| H5, HDF, HDF5 | `pd.read_hdf` |\n",
    "| JSON  | `pd.read_json` |\n",
    "| SQL | `pd.read_sql_table` |\n",
    "\n",
    "> These are all functions, which can be called, i.e. `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loading the Data\n",
    "\n",
    "The file can be local or **hosted**: The `read_*`-function have many options and are very high general (in the sense of broad or comprehensive) functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url_ecdc_daily_cases = \"https://opendata.ecdc.europa.eu/covid19/nationalcasedeath_eueea_daily_ei/csv/data.csv\"\n",
    "df = pd.read_csv(url_ecdc_daily_cases)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examining the Dataset\n",
    "\n",
    "Sometimes, we might just want to quickly inspect the DataFrame:\n",
    "\n",
    "#### Attributes\n",
    "```python\n",
    "df.shape    # Shape of the object (2D)\n",
    "df.dtypes   # Data types in each column\n",
    "df.index    # Index range\n",
    "df.columns  # Column names\n",
    "```\n",
    "\n",
    "#### Functions\n",
    "\n",
    "```python\n",
    "df.head()       # Displays first 5 rows\n",
    "df.tail()       # Displays last 5 rows\n",
    "df.sample()     # Displays randow 5 rows\n",
    "df.info()       # DataFrame information\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Shape\n",
    "\n",
    "The first dimension are the number of rows (the `len`gth of the `DataFrame`), the second dimension the number of features or columns. The direction going down the rows is `axis=0` or `axis='index'`, and going over the columns is `axis=1` or `axis='columns'`.\n",
    "\n",
    "axis | descriptions\n",
    "---  | ---\n",
    "0    | index\n",
    "1    | columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Index and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head, tail and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Renaming index/column names\n",
    "\n",
    "Data might come to us with index names, column names or othe naming conventions that do not fit our requirements.\n",
    "\n",
    "You can change those names to something more fitting, using the ```rename()``` function.\n",
    "\n",
    "If you want to change index names and/or column names, use the keyword ```index``` or ```columns```, respectively, and pass a dictionary with the original index/column name as key, and the new name as value.\n",
    "\n",
    "```python\n",
    "df.rename(columns={'A':'Column A', 'D':'Column D'})\n",
    "\n",
    "df.rename(index={0:'row1', 1:'row2', 100:'end row'})\n",
    "```\n",
    "\n",
    "You can also pass functions to ```rename()```:\n",
    "\n",
    "```python\n",
    "df.rename(index=str)           # Change the index data type to string\n",
    "\n",
    "df.rename(columns=str.lower)   # Make all column names lowercase\n",
    "```\n",
    "\n",
    "\n",
    "To keep the changes, set the ```inplace``` argument to ```True```, or store the changed DataFrame in a variable:\n",
    "\n",
    "```python\n",
    "df.rename(index=str, inplace=True)\n",
    "\n",
    "new_df = df.rename(index=str)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rename_df = df.rename(columns={'day':'Column day', 'deaths':'Column deaths'}, index={0:'row1', 1:'row2', 100:'end row'})\n",
    "rename_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Indexing and Selecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Native accessors\n",
    "\n",
    "Pandas has a lot of flexibility in the number of syntaxes it supports.  For example, to select columns in a DataFrame:\n",
    "\n",
    "```python\n",
    "df['Column1']\n",
    "df.Column1  # no whitespaces possible!\n",
    "```\n",
    "\n",
    "Multiple Columns can also be selected by providing a list:\n",
    "\n",
    "```python\n",
    "df[['Column1', 'Column2']]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['year', 'month', 'day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas accessors\n",
    "\n",
    "Accessor operators  **iloc** (index-based) and **loc** (label-based):\n",
    "\n",
    "```python\n",
    "df.iloc['5']     # df.iloc[row_index, column_index]\n",
    "df.loc['Row6']   # df.loc[row_label, column_label]\n",
    "```\n",
    "\n",
    "On its own, the \"**:**\" operator means \"everything\".\n",
    "\n",
    "When combined with other selectors, can be used to indicate a range of values.\n",
    "\n",
    "In **loc**, both start bound and the stop bound are inclusive, while in **iloc**, the stop bound is exclusive.\n",
    "\n",
    "![alt text](../figures/pandas_indexing.png \"Title\")\n",
    "\n",
    "<div style=\"text-align: right\"> From https://towardsdatascience.com/loc-vs-iloc-in-pandas-heres-the-difference-—16cd4bcbecab </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Index-based selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select an entire column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[:, 5]   # all rows, and 6th column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the first 3 rows of the 6th column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:3, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only the second and third rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:3, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select with a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[2, 3, 4, 5], 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use negative numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label-based selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:2, 'deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1:2, 'deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[2, 3, 4, 5], 'deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[22828:,['dateRep', 'cases', 'deaths', 'countriesAndTerritories']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In small DataFrames:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame(data, index=['row1', 'row2', 'row3', 'row4'], columns=['A', 'B', 'C'])\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```python\n",
    "df.index = ['row1', 'row2', 'row3', 'row4']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But in big DataFrames there are too many rows to make the above efficient.\n",
    "So we use ```set_index()```:\n",
    "\n",
    "```python\n",
    "df.set_index('Column1')\n",
    "```\n",
    "\n",
    "To keep the index change, store it as a variable:\n",
    "\n",
    "```python\n",
    "df = df.set_index('Column1')\n",
    "```\n",
    "\n",
    "or use the argument ```inplace=True```:\n",
    "\n",
    "```python\n",
    "df.set_index('Column1', inplace=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.set_index('countriesAndTerritories')\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df.loc['Denmark']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Display the first 5 lines of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Show the last 15 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Check 10 random lines of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Make a new dataframe containing just the date, population data and number of cases and deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Make a new dataframe containing just the 10th, 15th and 16th lines of the dataset. Which method did you use? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional selection\n",
    "\n",
    "#### Row selection\n",
    "Defining a condition with a Pandas DataFrame follows the same syntax:\n",
    "\n",
    "```python\n",
    "df['Column1'] > 0   # Return a Series of True and False\n",
    "```\n",
    "\n",
    "To filter the DataFrame for the rows where the value is ```True```:\n",
    "\n",
    "```python\n",
    "select_rows = df[df['Column1'] > 0]\n",
    "```\n",
    "or\n",
    "```python\n",
    "select_rows = df.loc[df['Column1'] > 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You can also filter based on multiple conditions, using the element-wise (\"bit-wise\") logical operators **`&`** data intersection, or **`|`** for the data union.\n",
    "\n",
    "```python\n",
    "select_rows = df[(df['Column1'] > 0) & (df['Column2'] > 2)]\n",
    "```\n",
    "or\n",
    "```python\n",
    "select_rows = df.loc[(df['Column1'] > 0) & (df['Column2'] > 2)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```python\n",
    "select_rows = df[(df['Column1'] > 0) | (df['Column2'] > 2)]\n",
    "```\n",
    "or\n",
    "```python\n",
    "select_rows = df.loc[(df['Column1'] > 0) | (df['Column2'] > 2)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider  first creating the mask (`Series` of `True` and `False` values indicating if a row is selected)\n",
    "\n",
    "```python\n",
    "mask = (df['Column1'] > 0) | (df['Column2'] > 2)\n",
    "select_rows = df[mask]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Row and Column selection\n",
    "\n",
    "```python\n",
    "select_df = df.loc[df['Column1'] > 0, ['Column1', 'Column2', 'Column3']]\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```python\n",
    "select_df = df[df['Column1'] > 0][['Column1', 'Column2', 'Column3']]\n",
    "```\n",
    "\n",
    "or \n",
    "\n",
    "```python\n",
    "select_df = df[['Column1', 'Column2', 'Column3']][df['Column1'] > 0]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using masks:\n",
    "\n",
    "```python\n",
    "row_mask = (df['Column1'] > 0) | (df['Column2'] > 2)\n",
    "column_mask = ['Column4', 'Column5']\n",
    "\n",
    "select_df = df.loc[row_mask, column_mask]\n",
    "\n",
    "```\n",
    "\n",
    "Checkout more interesting methods:\n",
    "- [`pandas.Series.isin`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.isin.html)\n",
    "- [`pandas.Series.betweeen`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.between.html?highlight=between#pandas.Series.between)\n",
    "- [`pandas.DataFrame.notnull`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.notnull.html)\n",
    "- [`pandas.DataFrame.isnull`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df['countriesAndTerritories'] == 'Denmark'] # This is not saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.loc[df['countriesAndTerritories']=='Denmark', ['dateRep', 'cases']]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "Make a new dataframe with the year, month, day, number of cases and deaths, for countries in Europe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With what you learned so far, how would you calculate average daily death cases for Austria?\n",
    "\n",
    "> We will solve together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary functions\n",
    "\n",
    "Pandas' Series and DataFrames are iterables, and can be given to any function that expects a list or Numpy Array, which allows them to be useful to many different libraries' functions.  For example, to compute basic statistics for a colum (`Series`):\n",
    "\n",
    "```python\n",
    "df.describe() # describe numeric columns\n",
    "df['Column1'].describe() # describe a particular column/series\n",
    "df['Column1'].count()    # counts non-NA cells\n",
    "df['Column1'].nunique()  # counts number of distinct elements in specified axis\n",
    "df['Column1'].unique()   # returns array of unique values of Series, in order of appearance\n",
    "df['Column1'].value_counts()  # returns list of unique values and how often they occur in the dataset\n",
    "\n",
    "df['Column1'].max()\n",
    "df['Column1'].mean()\n",
    "df['Column1'].idxmax()\n",
    "df['Column2'][df['Column1'] == 'string'].sum()\n",
    "```\n",
    "\n",
    "or for row:\n",
    "\n",
    "```python\n",
    "df.loc['row_index_label'].sum() # count, std, mean, etc\n",
    "```\n",
    "\n",
    "or for all columns\n",
    "\n",
    "```python\n",
    "df.mean() # default by column (= over all index)\n",
    "```\n",
    "\n",
    "or for all rows\n",
    "\n",
    "```python\n",
    "df.mean(axis=1)\n",
    "df.mean(axis='columns') # columns axis is axis 1\n",
    "```\n",
    "\n",
    "> What the default axis for a method (or operation) will vary.\n",
    "\n",
    "Example documentation: [`var`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.var.html#pandas.DataFrame.var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.mean()  # uses numeric column only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 4\n",
    "Which country has the maximum number of deaths reported on one day?\n",
    "> Hint: check [Pandas DataFrame API reference]('https://pandas.pydata.org/docs/reference/frame.html') for more useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many countries does europe have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many unique dates are in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the average daily death cases for Norway?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modifying Data\n",
    "\n",
    "Any transformation function can be performed on each element of a column   or on the entire DataFrame.\n",
    "\n",
    "You can assign a constant value:\n",
    "```python\n",
    "df['Column20'] = 10\n",
    "```\n",
    "\n",
    "An iterable of values:\n",
    "```python\n",
    "df['Column21'] = range(len(df), 0, -1)  # Replace the entire column with other values (length must match)\n",
    "```\n",
    "\n",
    "You can create a columns based on the transformation of another columns' numerical values:\n",
    "```python\n",
    "df['Column22'] = df['Column1'] * 5\n",
    "```\n",
    "\n",
    "Or modify strings:\n",
    "```python\n",
    "df['Column10'] = df['Column10'].str.upper()\n",
    "```\n",
    "\n",
    "Or even delete an entire column:\n",
    "```python\n",
    "del df['B']\n",
    "```\n",
    "\n",
    "> Column: a `pandas.Series` with the index of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Create new column based on the number of cases per 100.000 population\n",
    "df['cases_per_capita'] = df['cases'] / df['popData2020'] * 100000\n",
    "\n",
    "# Filter dataset to include only Denmark\n",
    "mask_denmark = df['countriesAndTerritories'] == 'Denmark'\n",
    "df[mask_denmark]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For more complicated operations, where you want to combine `DataFrame`s with `Series`, you can have a look [how broadcasting works](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#flexible-binary-operations) in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "Which country has most daily deaths per capita?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the median daily infection rate in Europe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Make the country code variable column lower-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Make a column called \"survived\", to be the opposite of the deaths column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## GroupBy Operations and Sorting\n",
    "\n",
    "In most of our tasks, getting single metrics from a dataset is not enough, and we often actually want to compare metrics between groups or conditions.\n",
    "\n",
    "The [**`groupby`**](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)\n",
    "method essentially splits the data into different groups depending on a variable of your choice, and allows you to apply summary functions on each group. For example, if you wanted to calculate the mean number of cases by month from a given our `DataFrame`:\n",
    "\n",
    "```python\n",
    "df.groupby('month').cases.mean()\n",
    "```\n",
    "where \"month\" is a column name from the [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html).\n",
    " \n",
    "You can also group by multiple columns, by providing a list of column names:\n",
    " \n",
    "```python\n",
    "df.groupby(['year', 'month']).cases.mean()\n",
    "```\n",
    "\n",
    "> Aggregating by multiple columns will create an [`MultiIndex`](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html) row-Index.  \n",
    "> You can access indices with more than one entry using tuples: `df.loc[(first_index, second_index)]`\n",
    "\n",
    "\n",
    "The `groupby` method returns a GroupBy object, where the `.groups` attribute is a dictionary whose keys are the computed unique groups.\n",
    "\n",
    "\n",
    "[`GroupBy`](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html) objects are **lazy**, meaning they don't start calculating anything until they know the full pipeline.  This approach is called the **\"Split-Apply-Combine\"** workflow.  You can get more info on it [in the UserGuide](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(by='countriesAndTerritories').cases.sum().loc['Denmark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[mask_denmark, 'cases'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What was the median number of daily cases per country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many days where there without deaths in each country?\n",
    "- select rows with zero deaths, group these and count the days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many infected daily on average for each country in each month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What was the infection rate for each country for the whole period?\n",
    "    \n",
    "> Consider infection rate is the number of infection per population size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multiple Statistics per Group\n",
    "\n",
    "Another piece of syntax we are going to look at, is the `aggregate` method for a `GroupBy` pandas objects, also available as `agg`.\n",
    "\n",
    "The aggregation functionality provided by this function allows multiple statistics to be calculated per group in one calculation.\n",
    "\n",
    "The instructions to the method `agg` are provided in the form of a dictionary, where the keys specify the columns upon which to apply the operation(s), and the value specify the function to run:\n",
    "\n",
    "```python\n",
    "df.groupby(['year', 'month']).agg({'duration':'sum',\n",
    "                                   'network_type':'count',\n",
    "                                   'date':'first'})\n",
    "```\n",
    "\n",
    "> Not a working example for our `DataFrame`\n",
    "\n",
    "You can also apply multiple functions to one column in groups:\n",
    "\n",
    "```python\n",
    "df.groupby(['year', 'month']).agg({'duration':[min, max, sum],\n",
    "                                   'network_type':'count',\n",
    "                                   'date':[min, 'first', 'nunique']})\n",
    "```\n",
    "\n",
    "> Aggregating by multiple columns will create an [`MultiIndex`](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html) row-Index.  \n",
    "> You can access indices with more than one entry using tuples: `df.loc[(first_index, second_index)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "new_df = df.groupby(by='countriesAndTerritories').agg({'cases': 'sum', 'popData2020': 'mean'})\n",
    "new_df['cases']/new_df['popData2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting\n",
    "\n",
    "Sort a dataset based on column values, with ```sort_values()```:\n",
    "\n",
    "```python\n",
    "df.sort_values(by='cases')\n",
    "```\n",
    "\n",
    "By default, values are sorted in ascending order (alhpabetically). To change to descending order, change the argument ```ascending``` to ```False```:\n",
    "\n",
    "```python\n",
    "df.sort_values(by='cases', ascending=False)\n",
    "```\n",
    "\n",
    "To sort the dataset based on index values, use the companion function ```sort_index()```. This function has the same arguments and default order:\n",
    "\n",
    "```python\n",
    "df.groupby(by='countriesAndTerritories').agg({'cases': 'sum', 'deaths': sum}).sort_index()\n",
    "```\n",
    "\n",
    "You can also sort by more than one column at a time:\n",
    "\n",
    "```python\n",
    "df.sort_values(by=['countriesAndTerritories', 'cases'], ascending=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 7\n",
    "\n",
    "Calculate how many were infected and how many survived daily on average all over Europe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many infected and survived daily on average for each country in each month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Missing values are often a concern in data science, for example in proteomics, and can be indicated with a **`None`** or **`NaN`** (np.nan in Numpy). Pandas DataFrames have several methods for detecting, removing and replacing these values:\n",
    "\n",
    "| method | description\n",
    "| ---:  | :---- |\n",
    "**`isna()`** | Returns True for each NaN |\n",
    "**`notna()`** | Returns False for each NaN |\n",
    "**`dropna()`** | Returns just the rows without any NaNs |\n",
    "\n",
    "Detect missing values and retrieve rows where they are present in column \"Column1\":\n",
    "\n",
    "```python\n",
    "missing_data_rows = df[df['Column1'].isna()]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imputation\n",
    "\n",
    "Imputation means replacing the missing values with real values. \n",
    "\n",
    "| method | description |\n",
    "| ----: |  :---- |\n",
    "| **`fillna()`** | Replaces the NaNs with values (provides lots of options) |\n",
    "| **`ffill()`** | Replaces the Nans with the previous non-NaN value (equivalent to df.fillna(method='ffill') |\n",
    "| **`bfill()`** | Replaces the Nans with the following non-NaN value (equivalent to df.fillna(method='bfill') |\n",
    "| **`interpolate()`** | interpolates nans with previous and following values |\n",
    "\n",
    "\n",
    "Replace missing values with constant value across dataset:\n",
    "```python\n",
    "df = df.fillna(0)\n",
    "```\n",
    "\n",
    "Replace missing values in a specific column:\n",
    "```python\n",
    "df['Column1'] = df['Column1'].fillna(0)\n",
    "```\n",
    "\n",
    "Replace missing values with specific values per column, using a dictionary:\n",
    "```python\n",
    "new_values = {'Column1': 0, 'Column2': 5, 'Column3': 'Unknown'}\n",
    "df = df.fillna(values=new_values)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 8\n",
    "\n",
    "Here we will use the titanic data which contains some missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "titanic = pd.read_csv(url)\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What proportion of the \"deck\" column is missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many rows don't contain any missing data at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Make a dataframe with only the rows containing no missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 9\n",
    "\n",
    "Using the following DataFrame, solve the exercises below.\n",
    "\n",
    "> recreate it in every exercise or copy it to avoid confusion:  `data_type_filled = data.copy()`  \n",
    "> Can you explain the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'time': [0.5, 1., 1.5, None, 2.5, 3., 3.5, None], 'value': [\n",
    "                    6, 4, 5, 8, None, 10, 11, None]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Replace all the missing \"value\" rows with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Replace the missing \"time\" rows with the previous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Replace all of the missing values with the data from the next row. What do you notice when you do this with this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Linearly interpolate the missing data. What is the result for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wide vs Long formats\n",
    "\n",
    "Two formats for Pandas DataFrames: wide and long.\n",
    "\n",
    "In the ```wide``` format, each feature (attribute) is a separate columns, while each row represents many features of the same individual entry. In the wide format, there are no repeated records, but there might be missing values. This format is preferable to perform statistics (e.g. mean).\n",
    "\n",
    "In the ```long``` format, each row only shows one feature for each individual entry, and there are multiple rows for each entry (one for each feature). We often use this format for graphic plotting.\n",
    "\n",
    "<table> <tr>\n",
    "<td style=\"background:white\"> <img src=\"../figures/wide_format.png\" alt=\"Drawing\" style=\"width: 450px;\"/> </td>\n",
    "<td style=\"background:white\"> <img src=\"../figures/long_format.png\" alt=\"Drawing\" style=\"width: 450px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "<div style=\"text-align: right\"> From https://www.statology.org/long-vs-wide-data/ </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Lambda and Mapping functions\n",
    "\n",
    "You can, of course, write your own functions in Python, but ```lambda``` functions are often a faster and easier way to write simple functions on the fly.\n",
    "\n",
    "To do so, you always start with the ```lambda``` keyword, followed by the names of the arguments, a colon and then the expression than specifies what we want the function to return. For example, if we want multiply two numbers:\n",
    "\n",
    "```python\n",
    "max_value = lambda x, y: x * y\n",
    "\n",
    "a = 55\n",
    "b = 34\n",
    "max_value(a, b)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "```lambda``` functions are especially useful when combined with mapping methods like ```map()``` and ```apply()```.\n",
    "\n",
    "The **map** term indicates a function that takes one set of values and \"maps\" them to another set of values. In data science, we often need to create new representations or transform existing data. mapping functions help us do this work.\n",
    "\n",
    "```map()``` is slightly simpler and takes in a function as argument, for example, a ```lambda``` function. Whatever function you pass though, make sure the expexted input is always a single value. The return of ```map()``` will be the original input value, transformed by the ```lambda``` function.\n",
    "\n",
    "```python\n",
    "\n",
    "average_cases = df.cases.mean()\n",
    "\n",
    "df.cases.map(lambda x: x - average_cases)  # Centers the data distribution of number of cases around 0.\n",
    "```\n",
    "\n",
    "Besides functions, ```map()``` can also accept dictionaries (key corresponds to input value, and dictionary value is the new value to replace the input one), and Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```apply()``` is the equivalent method but when we want to transform an entire DataFrame. It can be applied row-wise or column-wise, depending whether the argument ```axis``` is set to ```rows``` or ```columns```, respectively.\n",
    "\n",
    "```python\n",
    "average_cases = df.cases.mean()\n",
    "\n",
    "def center_mean(data):\n",
    "    data.cases = data.cases - average_cases\n",
    "    return data\n",
    "\n",
    "df.apply(center_mean, axis='columns')\n",
    "```\n",
    "\n",
    "Differently from ```map()```, ```apply()``` also allows passing of positional or keyword arguments to the function.\n",
    "\n",
    "```python\n",
    "def get_deaths_class(value, lower_threshold, upper_threshold):\n",
    "    if value >= int(upper_threshold):\n",
    "        class_name = 'High'\n",
    "    elif value <= int(lower_threshold):\n",
    "        class_name = 'Low'\n",
    "    else:\n",
    "        class_name = 'Moderate'\n",
    "        \n",
    "    return class_name\n",
    "        \n",
    "df['deaths_class'] = df['deaths'].apply(get_deaths_class, lower_threshold = 20, upper_threshold = 100)\n",
    "```\n",
    "\n",
    "You can also use the ```apply()``` method in a group-wise analysis:\n",
    "\n",
    "```python\n",
    "df.groupby(['countriesAndTerritories', 'year', 'month']).apply(lambda df: df.loc[df.cases.idxmax()])\n",
    "```\n",
    "\n",
    "\n",
    "For more information of these methods and more, go to [Pandas API reference]('https://pandas.pydata.org/docs/reference/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining DataFrames\n",
    "\n",
    "When performing operations on a dataset, we might sometimes need to combine different DataFrames and/or other Series. Pandas has a few functions that allows to do that: ```concat()```, ```join()```, and ```merge()```.\n",
    "\n",
    "```concat()``` is the simplest combining methods. It will smush together all the elements in a list, along a specified axis.\n",
    "\n",
    "```python\n",
    "data1 = {'id': ['1', '2', '3', '4', '5'],\n",
    "         'Column1': ['A', 'C', 'E', 'G', 'I']}\n",
    "df1 = pd.DataFrame(data1, columns = ['id', 'Column1'])\n",
    "\n",
    "data2 = {'id': ['1', '2', '6', '7', '8'],\n",
    "         'Column1': ['K', 'M', 'O', 'Q', 'S'],\n",
    "         'Column2': ['L', 'N', 'P', 'R', 'T']}\n",
    "df2 = pd.DataFrame(data2, columns = ['id', 'Column1', 'Column2'])\n",
    "\n",
    "combined_df_rows = pd.concat([df1, df2], ignore_index=True)   # Concatenates along the row and adjusts row\n",
    "                                                              # labels automatically with \"ignore_index=True\"\n",
    "\n",
    "combined_df_columns = pd.concat([df1, df2], axis=1)   # Concatenates along the columns\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```merge()``` and ```join()``` can do similar operations, but ```join()``` is often easier to apply. These are used when DataFrames hold different kinds of information about the same entity, linked by some common feature.\n",
    "\n",
    "To combine on the common column, use the argument ```on``` and set it to the common column name:\n",
    "\n",
    "```python\n",
    "data3 = {'id': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "         'Feature3': [12, 13, 14, 15, 16, 17, 15, 12, 13, 23]}\n",
    "df3 = pd.DataFrame(data3, columns = ['id', 'Feature3'])\n",
    "\n",
    "merger_df = pd.merge(combined_df_rows, df3, on='id')\n",
    "```\n",
    "\n",
    "Sometimes, the column on which you want to merge has different names. If that is the case, you can specify the arguments ```left_on``` and ```right_on``` for the left DataFrame and right DataFrame column names, respectively:\n",
    "\n",
    "```python\n",
    "data3 = {'identifier': ['1', '2', '3', '4', '5', '7', '8', '9', '10', '11'],\n",
    "         'Feature3': [12, 13, 14, 15, 16, 17, 15, 12, 13, 23]}\n",
    "df3 = pd.DataFrame(data3, columns = ['identifier', 'Feature3'])\n",
    "\n",
    "merger_df = pd.merge(combined_df_rows, df3, left_on='id', right_on='identifier')\n",
    "```\n",
    "\n",
    "At the same time, you can also decide what kind of join logics you want to use:\n",
    "\n",
    "- Full outer join: ```how = outer```\n",
    "- Inner join: ```how = inner```\n",
    "- Right join: ```how = right```\n",
    "- Left join: ```how = left```\n",
    "\n",
    "\n",
    "For more information and an easy to visualize guide for these methods, please check this link [this link](https://pandas.pydata.org/docs/user_guide/merging.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ol5el84hJ9oQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Extra exercises\n",
    "\n",
    "> Might include usage of other packages, including numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simple vectorized operations\n",
    "\n",
    "You want to plot the mathematical function\n",
    "\n",
    "$f(x) = log(-1.3x^2 + 1.4^x + 7x + 50)$\n",
    "\n",
    "For the numbers in $[0, 20]$. To do this, you need to create a vector `xs` with lots of numbers between 0 and 20, and a vector `ys` with $f$ evaluated at every element of `xs`. A vector is a `1d-ndarray`.\n",
    "\n",
    "To get a hang of vectorized operations, solve the problem *without using any loops*:\n",
    "\n",
    "### Create a `pandas.Series` `xs` with 1000 evenly spaced points between 0 and 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Create a Python function $f$ as seen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Evaluate `ys` = $f(x)$, i.e. $f$ of every element of `xs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What is the mean and standard deviation of `ys`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### How many elements of. `ys` are below 0? Between 1 and 2, both exclusive?\n",
    "\n",
    "> Hint: You can use a comparison operator to get an array of dtype `bool`. To get the number of elements that are `True`, you can exploit the fact that `True` behaves similar to the number 1, and `False` similar to the number 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What is the minimum and maximum value of `ys`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Create a series `non_negatives`, which contain all the values of `ys` that are nonnegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### *Extra*: Use `matplotlib` to plot `xs` vs `ys` directly from your `Series` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Species depth matrix\n",
    "\n",
    "Load in the data [`depths.csv`](https://drive.google.com/file/d/1d5694Ggnc-wq-ta0njlA9cz0_AEVQLoN/view). As you can see in drive preview, there are 11 columns, with columns 2-11 representing a sample from a human git microbiome. Each row represents a genome of a micro-organism, a so-called \"operational taxonomic unit at 97% sequence identity\" (OTU_97). The first row gives the name of the genome. The values in the matrix represents the relative abundance (or depth) of that micro-organism in that sample, i.e. how much of the micro-organism there is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Load in the matrix in a `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/Center-for-Health-Data-Science/PythonTsunami/fall2021/data/depths.csv'\n",
    "depths = pd.read_csv(url)\n",
    "depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How many OTUs are there? Show how you figured it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Find the OTU \"OTU_97.41189.0\". What is the mean and standard deviations of the depths across the 10 samples of this OTU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How many samples have 0 depth of that OTU? (or rather, below detection limit?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is the mean and standard deviation if you exclude those samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Extra: How would you get all the means and std. deviations in one go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### We are not interested in OTUs present in fewer than 4 samples. Remove all those OTUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How many OTUs did you remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How many OTUs have a depth of > 5 in all 10 samples? (hint: `np.all`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Filtering and Normalization\n",
    "\n",
    "After discarding all OTUs present in fewer than 4 samples, sort the OTUs, do the following:\n",
    "\n",
    "- Calculate the mean depth across samples for each remaining OTU.\n",
    "   \n",
    "- Normalize the remaining OTUs such that each row sum to 0 and have a standard deviation of 1 (so-called z-score normalization)\n",
    "- Print the remaining OTUs to a new file in descending order by their mean depth, with a 12th column giving the mean depth, and columns 1-11 being the normalized depth. Make sure that your file looks like the input file (except with the 12th column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "rise": {
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1149px",
    "left": "1987.61px",
    "top": "0px",
    "width": "572.391px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
