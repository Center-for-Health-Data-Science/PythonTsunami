{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"../figures/HeaDS_logo_large_withTitle.png\" width=\"300\">\n",
    "\n",
    "<img src=\"../figures/tsunami_logo.PNG\" width=\"600\">\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Center-for-Health-Data-Science/PythonTsunami/blob/fall2021/Pandas/Pandas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pandas\n",
    "\n",
    "*Prepared by [Rita ColaÃ§o](https://www.cpr.ku.dk/staff/?id=621366&vis=medarbejder) and [Henry Webel](https://twitter.com/Henrywebel)\n",
    "\n",
    "[Pandas cheat sheet](https://github.com/Center-for-Health-Data-Science/PythonTsunami/blob/fall2021/cheat_sheets/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Pandas is built on top of `numpy`. It has an interface to directly plot using `maptlotlib`.\n",
    "\n",
    "Pandas is well suited for tabular data with heterogeneously-typed columns, as in an Excel spreadsheet\n",
    "\n",
    "Pandas is a library for data analysis and its powertool is the **`DataFrame`**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Two main classes (types/ objects)\n",
    "\n",
    "1. `pandas.Series`\n",
    "2. `pandas.DataFrame`\n",
    "\n",
    "- a `Series` is a `numpy.array` with an `Index` series.\n",
    "- a column in a `DataFrame` is a `Series`.\n",
    "- columns in a `DataFrame` share an `Index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating an instance of a `pandas.Series`\n",
    "\n",
    "There are many ways. But a Series is an object holding some data.\n",
    "\n",
    "Let's create a Series from a built-in `range` and a `numpy.arange` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "series_range = pd.Series(range(3, 13))\n",
    "series_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "series_np_arange = pd.Series(np.arange(3, 13))\n",
    "series_np_arange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Series from range, underlying data:\\t\", series_range.values)\n",
    "print(\"Series from np.arange underlying data:\\t\", series_np_arange.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "series_range.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "series_np_arange.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is a DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A DataFrame is basically, a **Table** of data (or a tabular data structure) with labeled rows and columns. The rows are labeled by a special data structure called an Index, that permits fast look-up and powerful relational operations.\n",
    "For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "|  | Name | Age | Height | LikesIceCream |\n",
    "| :---: | :--: | :--: | :--: | :--: |\n",
    "| 0     | \"Nick\" | 22 | 3.4 | True |\n",
    "| 1     | \"Jenn\" | 55 | 1.2 | True |\n",
    "| 2     | \"Joe\"  | 25 | 2.2 | True |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Create a DataFrame directly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### From a `list` of `list`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    [2.23, 1, \"test\"],\n",
    "    [3.45, 2, \"train\"],\n",
    "    [4.5, 3, \"test\"],\n",
    "    [6.0, 4, \"train\"]\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### From a `list` of `dict`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = [\n",
    "    {'A': 2.23, 'B': 1, 'C': \"test\"},\n",
    "    {'A': 3.45, 'B': 2, 'C': \"train\"},\n",
    "    {'A': 4.5, 'B': 3, 'C': \"test\"},\n",
    "    {'A': 6.0, 'B': 4, 'C': \"train\"}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### From a Dict of Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'A': [2.23, 3.45, 4.5, 6.0],\n",
    "    'B': [1, 2, 3, 4],\n",
    "    'C': [\"test\", \"train\", \"test\", \"train\"]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### From a `dict` of `dict`s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'row1': {'A': 2.23, 'B': 1, 'C': \"test\"},\n",
    "        'row3': {'A': 3.45, 'B': 2, 'C': \"train\"},\n",
    "        'row2': {'A': 4.5, 'B': 3, 'C': \"test\"},\n",
    "        'row4': {'A': 6.0, 'B': 4, 'C': \"train\"}\n",
    "    },\n",
    "    orient='index'  # default is columns. pd.DataFrame also works, but you have to transpose the data\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### From an empty `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['A'] = [2.23, 3.45, 4.5, 6.0]\n",
    "df['B'] = [1, 2, 3, 4]\n",
    "df['C'] = [\"test\", \"train\", \"test\", \"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 1\n",
    "Please recreate the table below as a Dataframe using one of the approaches detailed above:\n",
    "\n",
    "|  | Year | Product | Cost |\n",
    "| ---| :--: | :----:  | :--: |\n",
    "| 0  | 2015 | Apples  | 0.35 |\n",
    "| 1  | 2016 | Apples  | 0.45 |\n",
    "| 2  | 2015 | Bananas | 0.75 |\n",
    "| 3  | 2016 | Bananas | 1.10 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Which approach did you prefer? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading data into `DataFrame`s from a file\n",
    "\n",
    "Pandas has functions that can make DataFrames from a wide variety of file types.  To do this, use one of the functions in Pandas that start with `read_`.  Here is a non-exclusive list of examples:\n",
    "\n",
    "| File Type | Function Name |\n",
    "| :----:    |  :---:  |\n",
    "| Excel | `pd.read_excel` |\n",
    "| CSV, TSV | `pd.read_csv` |\n",
    "| H5, HDF, HDF5 | `pd.read_hdf` |\n",
    "| JSON  | `pd.read_json` |\n",
    "| SQL | `pd.read_sql_table` |\n",
    "\n",
    "> These are all functions, which can be called, i.e. `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Loading the Data\n",
    "\n",
    "The file can be local or **hosted**: The `read_*`-function have many options and are very high general (in the sense of broad or comprehensive) functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url_ecdc_daily_cases = \"https://opendata.ecdc.europa.eu/covid19/nationalcasedeath_eueea_daily_ei/csv/data.csv\"\n",
    "df = pd.read_csv(url_ecdc_daily_cases)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Examining the Dataset\n",
    "\n",
    "Sometimes, we might just want to quickly inspect the DataFrame:\n",
    "\n",
    "### Attributes\n",
    "```python\n",
    "df.shape    # Shape of the object (2D)\n",
    "df.dtypes   # Data types in each column\n",
    "df.index    # Index range\n",
    "df.columns  # Column names\n",
    "```\n",
    "\n",
    "### Methods\n",
    "\n",
    "```python\n",
    "df.describe()   # Descriptive statistics of columns\n",
    "df.info()       # DataFrame information\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Shape\n",
    "\n",
    "The first dimension are the number of rows (the `len`gth of the `DataFrame`), the second dimension the number of features or columns. The direction going down the rows is `axis=0` or `axis='index'`, and going over the columns is `axis=1` or `axis='columns'`.\n",
    "\n",
    "axis | descriptions\n",
    "---  | ---\n",
    "0    | index\n",
    "1    | columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.shape  # axis=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Index and Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can set the index using `set_index`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.set_index('dateRep') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Info and describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "_ = df.info()  # returns None, only prints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()  # returns a new DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "'popData2020'## Selecting Data\n",
    "\n",
    "Pandas has a lot of flexibility in the number of syntaxes it supports.  For example, to select columns in a DataFrame:\n",
    "\n",
    "```python\n",
    "df['Column1']\n",
    "df.Column1  # no whitespaces possible!\n",
    "```\n",
    "\n",
    "Multiple Columns can also be selected by providing a list:\n",
    "\n",
    "```python\n",
    "df[['Column1', 'Column2']]\n",
    "```\n",
    "\n",
    "Rows are selected with the **iloc** and **loc** attributes:\n",
    "\n",
    "```python\n",
    "df.iloc[5]  # Used to get the \"integer\" index of the row.\n",
    "df.loc['Row6']  # Used if rows are named.\n",
    "```\n",
    "\n",
    "However, with large DataFrames, we often just want to see the first or last rows, or even just a sample of the rows.\n",
    "\n",
    "| Method | Description |\n",
    "| ---  | --- |\n",
    "| `df.head(5)` | the first 5 rows |\n",
    "| `df.tail(5)` | the last 5 rows |\n",
    "| `df.sample(5)` | a random 5 rows |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Back to the Covid19 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Display the first 5 lines of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Show the last 15 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Check 10 random lines of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Make a new dataframe containing just the date, population data and cases per capita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Make a new dataframe containing just the 10th, 15th and 16th lines of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Query/Filtering Data\n",
    "\n",
    "To get rows based on their value, Pandas supports both Numpy's logical indexing:\n",
    "\n",
    "```python\n",
    "select_rows = df[df['Column1'] > 0]\n",
    "```\n",
    "\n",
    "and an SQL-like query string:\n",
    "    \n",
    "```python\n",
    "df.query('Colummn1 > 0')\n",
    "```\n",
    "\n",
    "One can also filter based on multiple conditions, using the element-wise (\"bit-wise\") logical operators **`&`** data intersection, or **`|`** for the data union.\n",
    "\n",
    "```python\n",
    "select_rows = df[(df['Column1'] > 0) & (df['Column2'] > 2)]\n",
    "```\n",
    "\n",
    "```python\n",
    "select_rows = df[(df['Column1'] > 0) | (df['Column2'] > 2)]\n",
    "```\n",
    "\n",
    "consider  first creating the mask (`Series` of `True` and `False` values indicating if a row is selected)\n",
    "\n",
    "```python\n",
    "mask = (df['Column1'] > 0) | (df['Column2'] > 2)\n",
    "select_rows = df[mask]\n",
    "```\n",
    "\n",
    "Checkout the methods [`pandas.Series.isin`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.isin.html) or  [`pandas.Series.betweeen`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.between.html?highlight=between#pandas.Series.between)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df[df['countriesAndTerritories'] == 'Denmark'] # This is not saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "What the average daily death cases for Norway?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summarizing/Statistics in DataFrames\n",
    "\n",
    "Pandas' Series and DataFrames are iterables, and can be given to any function that expects a list or Numpy Array, which allows them to be useful to many different libraries' functions.  For example, to compute basic statistics for a colum (`Series`):\n",
    "\n",
    "```python\n",
    "df.describe() # describe numeric columns\n",
    "df['Column1'].describe() # describe a particular column/series\n",
    "df['Column1'].count()\n",
    "df['Column1'].nunique()\n",
    "df['Column1'].value_counts()\n",
    "\n",
    "df['Column1'].max()\n",
    "df['Column1'].mean()\n",
    "df['Column2'][df['Column1'] == 'string'].sum()\n",
    "```\n",
    "\n",
    "or for row:\n",
    "\n",
    "```python\n",
    "df.loc['row_index_label`].sum() # count, std, mean, etc\n",
    "```\n",
    "\n",
    "or for all columns\n",
    "\n",
    "```python\n",
    "df.mean() # default by column (= over all index)\n",
    "```\n",
    "\n",
    "or for all rows\n",
    "\n",
    "```python\n",
    "df.mean(axis=1)\n",
    "df.mean(axis='columns') # columns axis is axis 1\n",
    "```\n",
    "\n",
    "> What the default axis for a method (or operation) will vary.\n",
    "\n",
    "Example documentation: [`value_counts`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.mean()  # uses numeric column only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "You can also use the [`pipe`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pipe.html?highlight=pipe) method to call a function on the rows or columns of a DataFrame:\n",
    "\n",
    "```python\n",
    "df['Column1'].pipe(np.mean)\n",
    "```\n",
    "\n",
    "method | description\n",
    "--- | ---\n",
    "[`DataFrame.apply`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.apply.html#pandas.DataFrame.apply) | Apply a function along input axis of DataFrame.\n",
    "[`DataFrame.applymap`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.applymap.html#pandas.DataFrame.applymap) | Apply a function elementwise on a whole DataFrame.\n",
    "[`Series.map`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.map.html#pandas.Series.map) | Apply a mapping correspondence on a Series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 4\n",
    "Which country has the maxiumum number of deaths reported on one day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many countries does europe have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many unique days are in this data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transforming/Modifying Data\n",
    "\n",
    "Any transformation function can be performed on each element of a column   or on the entire DataFrame. For example:\n",
    "\n",
    "\n",
    "```python\n",
    "df['Column1'] * 5\n",
    "\n",
    "np.sqrt(df['Column1'])\n",
    "\n",
    "df['Column1'].str.upper()\n",
    "\n",
    "del df['B']\n",
    "\n",
    "df['Column1'] = [3, 9. 27, 81]  # Replace the entire column with other values (length must match)\n",
    "```\n",
    "\n",
    "> Column: a `pandas.Series` with the index of the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "col_population = 'popData2020'\n",
    "df['cases_per_capita'] = df['cases'] / df[col_population] * 100_000\n",
    "mask_denmark = df['countriesAndTerritories'] == 'Denmark'\n",
    "df[mask_denmark]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For more complicated operations, where you want to combine `DataFrame`s with `Series`, you can have a look [how broadcasting works](https://pandas.pydata.org/pandas-docs/stable/user_guide/basics.html#flexible-binary-operations) in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 5\n",
    "\n",
    "Which country has most daily deaths per capita?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is the median daily infection rate in Europe? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make one country code variable column lower-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Make a columns called \"survived\", the opposite as opposite to the deaths column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## GroupBy Operations\n",
    "\n",
    "In most of our tasks, getting single metrics from a dataset is not enough, and we often actually want to compare metrics between groups or conditions.\n",
    "\n",
    "The [**`groupby`**](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)\n",
    "method essentially splits the data into different groups depending on a variable of your choice, and allows you to apply summary functions on each group. For example, if you wanted to calculate the mean temperature by month from a given data frame:\n",
    "\n",
    "```python\n",
    "df.groupby('month').temperature.mean()\n",
    "```\n",
    "where \"month\" and \"temperature\" are column names from the [`DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/frame.html).\n",
    " \n",
    "You can also group by multiple columns, by providing a list of column names:\n",
    " \n",
    "```python\n",
    "df.groupby(['year', 'month']).temperature.mean()\n",
    "```\n",
    "\n",
    "The `groupby` method returns a GroupBy object, where the `.groups` attribute is a dictionary whose keys are the computed unique groups.\n",
    "\n",
    "\n",
    "[`GroupBy`](https://pandas.pydata.org/pandas-docs/stable/reference/groupby.html) objects are **lazy**, meaning they don't start calculating anything until they know the full pipeline.  This approach is called the **\"Split-Apply-Combine\"** workflow.  You can get more info on it [in the UserGuide](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(by='countriesAndTerritories').cases.sum().loc['Denmark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[mask_denmark, 'cases'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What proportion of days where withouth deaths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many days where there withouth deaths in each country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What was the median number of daily cases per country?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What was the infection rate for each country for the whole period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many infected daily on average for each country in each month?\n",
    "\n",
    "> Multiclass Index ([guide](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html):\n",
    "> You can access indices with more than one entry using tuples: `df.loc[(first_index, second_index)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multiple Statistics per Group\n",
    "\n",
    "Another piece of syntax we are going to look at, is the `aggregate` method for a `GroupBy` pandas objects, also available as `agg`.\n",
    "\n",
    "The aggregation functionality provided by this function allows multiple statistics to be calculated per group in one calculation.\n",
    "\n",
    "The instructions to the method `agg` are provided in the form of a dictionary, where the keys specify the columns upon which to apply the operation(s), and the value specify the function to run:\n",
    "\n",
    "```python\n",
    "df.groupby(['year', 'month']).agg({'duration':'sum',\n",
    "                                   'network_type':'count',\n",
    "                                   'date':'first'})\n",
    "```\n",
    "\n",
    "You can also apply multiple functions to one column in groups:\n",
    "\n",
    "```python\n",
    "df.groupby(['year', 'month']).agg({'duration':[min, max, sum],\n",
    "                                   'network_type':'count',\n",
    "                                   'date':[min, 'first', 'nunique']})\n",
    "```\n",
    "\n",
    "> Aggregating by multiple columns will create an [`MultiIndex`](https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html) row-Index.  \n",
    "> You can access indices with more than one entry using tuples: `df.loc[(first_index, second_index)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.groupby(by='countriesAndTerritories').agg(\n",
    "    {'cases': 'sum', 'deaths': sum})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 7\n",
    "\n",
    "How many infected and survived daily on average all over Europe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many infected and survived daily on average for each country in each month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling Missing Values\n",
    "\n",
    "Missing values are often a concern in data science, for example in proteomics, and can be indicated with a **`None`** or **`NaN`** (np.nan in Numpy). Pandas DataFrames have several methods for detecting, removing and replacing these values:\n",
    "\n",
    "| method | description\n",
    "| ---:  | :---- |\n",
    "**`isna()`** | Returns True for each NaN |\n",
    "**`notna()`** | Returns False for each NaN |\n",
    "**`dropna()`** | Returns just the rows without any NaNs |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Imputation\n",
    "\n",
    "Imputation means replacing the missing values with real values. \n",
    "\n",
    "| method | description |\n",
    "| ----: |  :---- |\n",
    "| **`fillna()`** | Replaces the NaNs with values (provides lots of options) |\n",
    "| **`ffill()`** | Replaces the Nans with the previous non-NaN value (equivalent to df.fillna(method='ffill') |\n",
    "| **`bfill()`** | Replaces the Nans with the following non-NaN value (equivalent to df.fillna(method='bfill') |\n",
    "| **`interpolate()`** | interpolates nans with previous and following values |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 8\n",
    "\n",
    "Here we will use the titanic data which contains some missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv'\n",
    "titanic = pd.read_csv(url)\n",
    "titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What proportion of the \"deck\" column is missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How many rows don't contain any missing data at all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Make a dataframe with only the rows containing no missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise 9\n",
    "\n",
    "Using the following DataFrame, solve the exercises below.\n",
    "\n",
    "> recreate it in every exercise or copy it to avoid confusion:  `data_type_filled = data.copy()`  \n",
    "> Can you explain the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'time': [0.5, 1., 1.5, None, 2.5, 3., 3.5, None], 'value': [\n",
    "                    6, 4, 5, 8, None, 10, 11, None]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Replace all the missing \"value\" rows with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Replace the missing \"time\" rows with the previous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Replace all of the missing values with the data from the next row. What do you notice when you do this with this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Linearly interpolate the missing data. What is the result for this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------\n",
    "----------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ol5el84hJ9oQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Optional: Redo-exercises from numpy \n",
    "\n",
    "> What is different?\n",
    "\n",
    "In all of these exercises, do not loop over `Series` you create. All exercises can be solved using only vectorized operations on a `Series` or `DataFrame`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Simple vectorized operations\n",
    "\n",
    "You want to plot the mathematical function\n",
    "\n",
    "$f(x) = log(-1.3x^2 + 1.4^x + 7x + 50)$\n",
    "\n",
    "For the numbers in $[0, 20]$. To do this, you need to create a vector `xs` with lots of numbers between 0 and 20, and a vector `ys` with $f$ evaluated at every element of `xs`. A vector is a `1d-ndarray`.\n",
    "\n",
    "To get a hang of vectorized operations, solve the problem *without using any loops*:\n",
    "\n",
    "### Create a `pandas.Series` `xs` with 1000 evenly spaced points between 0 and 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Create a Python function $f$ as seen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Evaluate `ys` = $f(x)$, i.e. $f$ of every element of `xs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What is the mean and standard deviation of `ys`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### How many elements of. `ys` are below 0? Between 1 and 2, both exclusive?\n",
    "\n",
    "> Hint: You can use a comparison operator to get an array of dtype `bool`. To get the number of elements that are `True`, you can exploit the fact that `True` behaves similar to the number 1, and `False` similar to the number 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### What is the minimum and maximum value of `ys`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Create a series `non_negatives`, which contain all the values of `ys` that are nonnegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8lcv9BwJ9oQ",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### *Extra*: Use `matplotlib` to plot `xs` vs `ys` directly from your `Series` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Species depth matrix\n",
    "\n",
    "Load in the data [`depths.csv`](https://drive.google.com/file/d/1d5694Ggnc-wq-ta0njlA9cz0_AEVQLoN/view). As you can see in drive preview, there are 11 columns, with columns 2-11 representing a sample from a human git microbiome. Each row represents a genome of a micro-organism, a so-called \"operational taxonomic unit at 97% sequence identity\" (OTU_97). The first row gives the name of the genome. The values in the matrix represents the relative abundance (or depth) of that micro-organism in that sample, i.e. how much of the micro-organism there is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Load in the matrix in a `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/pythontsunami/teaching/fall2021/data/depths.csv'\n",
    "depths = pd.read_csv(url)\n",
    "depths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How many OTUs are there? Show how you figured it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Find the OTU \"OTU_97.41189.0\". What is the mean and standard deviations of the depths across the 10 samples of this OTU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How many samples have 0 depth of that OTU? (or rather, below detection limit?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What is the mean and standard deviation if you exclude those samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Extra: How would you get all the means and std. deviations in one go?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### We are not interested in OTUs present in fewer than 4 samples. Remove all those OTUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How many OTUs did you remove?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How many OTUs have a depth of > 5 in all 10 samples? (hint: `np.all`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Filtering and Normalization\n",
    "\n",
    "After discarding all OTUs present in fewer than 4 samples, sort the OTUs, do the following:\n",
    "\n",
    "- Calculate the mean depth across samples for each remaining OTU.\n",
    "   \n",
    "- Normalize the remaining OTUs such that each row sum to 0 and have a standard deviation of 1 (so-called z-score normalization)\n",
    "- Print the remaining OTUs to a new file in descending order by their mean depth, with a 12th column giving the mean depth, and columns 1-11 being the normalized depth. Make sure that your file looks like the input file (except with the 12th column)\n",
    "\n",
    "> Do the results match with what you computed before using `numpy`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "rise": {
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "1149px",
    "left": "1987.61px",
    "top": "0px",
    "width": "572.391px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
