{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Pandas: Working with Different File types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas library offers a wide range of possibilities for creating, writing and reading files. There are two types of files that can be handled in Python, normal text files and binary files.\n",
    "\n",
    "\n",
    "In this notebook we will learn more about working with these different formats: CSV, Excel, JSON, HTML, SQL, Pickle, Matlab .mat, and HDF5 files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File I/O Operations\n",
    "\n",
    "In Python, a physical file must be mapped to a built-in file object with the help of built-in function **open()**.\n",
    "\n",
    "In this function, the first parameter is the **name of a file including its path**. The **access mode** parameter is an optional parameter, which refers to how the file will be used once its opened. The following table lists the valid values of access mode parameters:\n",
    "\n",
    "| mode | format | read/write | create new file? | comments |\n",
    "| :--: | :--:   | :--:       | :--:             | :--:     |\n",
    "| 'r'    | text   | read | no | Default mode |\n",
    "| 'rb'   | binary | read | no | Raises I/O error if the file does not exist |\n",
    "| 'r+'   | text   | read/write  | no | Raises I/O error if the file does not exist |\n",
    "| 'rb+'   | binary | read/write | no | Raises I/O error if the file does not exist|\n",
    "| 'w'    | text   | write | yes | Truncates and overwrites data if file exists |\n",
    "| 'wb'    | binary   | write | yes | Truncates and overwrites data if file exists |\n",
    "| 'w+'   | text   | read/write | yes | Truncates and overwrites data if file exists |\n",
    "| 'wb+'    | binary   | write | yes | Truncates and overwrites data if file exists |\n",
    "| 'a'    | text   | write | yes | Data is inserted at the end of the file |\n",
    "| 'ab'    | binary   | write | no | Data is inserted at the end of the file |\n",
    "| 'a+'   | text   | read/write | yes | Data is inserted at the end of the file |\n",
    "| 'ab+'    | binary   | write | no | Data is inserted at the end of the file |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In text files, each line of text is terminated with a special character called EOL (End Of Line), which is the new line character ('**\\n**') by default, in python. In this section we will learn how to open, close, read and write data in a text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing to a File\n",
    "\n",
    "In order to write a physical file, you can run:\n",
    "\n",
    "```python\n",
    "f = open('file.txt', 'w')\n",
    "f.write('Hello, World!')\n",
    "f.close()\n",
    "```\n",
    "\n",
    "This code opens the file *file.txt* in the write mode, or creates it if it doesn't exist, and assigns it to a variable **f**. To add data to the file, we use **write()**, and in the end, **close()** closes the file object.\n",
    "\n",
    "There is another method **writelines()** that saves the contents of a list object in a file. In this case, the newline character must be provided as part of the string:\n",
    "\n",
    "```python\n",
    "lines = ['Hello world.\\n', 'Welcome to the Python Tsunani.\\n']\n",
    "f = open('file.txt', 'w')\n",
    "f.writelines(lines)\n",
    "f.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from a File\n",
    "\n",
    "There are three different methods to read data from a file:\n",
    "\n",
    "1. **readline()**: reads the characters from the current position until the next newline character.\n",
    "\n",
    "2. **read()**: reads the specified number of characters.\n",
    "\n",
    "3. **readlines()**: reads all lines until the end of the file and returns a list.\n",
    "\n",
    "For example:\n",
    "\n",
    "```python\n",
    "f = open('file.txt', 'r')\n",
    "line = f.readline()\n",
    "f.close()\n",
    "```\n",
    "\n",
    "This piece of code will read the first line of the *file.txt* file and assign it to the variable *line*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you can to iterate over all lines of the file and read it easily. You can use:\n",
    "\n",
    "```python\n",
    "f = open('fiel.txt', 'r')\n",
    "for line in f:\n",
    "    print(line)\n",
    "    # Other relevant code\n",
    "f.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append Text to a File\n",
    "\n",
    "One of the particularities of the write mode **\"w\"** is that it will always treat the specified file as a new file. This means, if the file already exists and contains data, opening it with the \"w\" mode will make you lose its earlier contents.\n",
    "\n",
    "In order to add more data to and existing file, the better approach is to use the **\"a\"** or **\"a+\"** mode, like in the example:\n",
    "\n",
    "```python\n",
    "f = open('file.txt', 'a+')\n",
    "f.write('Hello! Learn Python with us.')\n",
    "line = f.readline()\n",
    "f.close()\n",
    "```\n",
    "\n",
    "In this example, we use the mode **\"a+\"** in order to perform simultaneous read/append operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV (Comma-Separated Values) Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A CSV file is a plaintext file with a .csv extension that holds tabular data. This is one of the most popular file formats for storing large amounts of data. \n",
    "\n",
    "Each line of the file represents one record, and the fields are, by default, separated by commas, but you could change the separator to a semicolon, tab, space, or some other character. If the fields are labelled, the first line pf the file (referred to as \"header\") will contain the field names.\n",
    "\n",
    "Example of CSV file:\n",
    "```\n",
    "month,height,weight\n",
    "Jan,1.2,76\n",
    "Feb,1.21,77\n",
    "March,1.21,76\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read CSV files, python comes with a csv reader that works quite well.\n",
    "\n",
    "```python\n",
    "import csv\n",
    "\n",
    "with open('file.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    data = list(reader)\n",
    "```\n",
    "\n",
    "Once you have read the data, it can go to a DataFrame, for example:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=header)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the Pandas csv read function **pandas.read_csv()**, which can get the data into a DataFrame. This is what we usually use.\n",
    "\n",
    "The major advantage of this function is that it has a lot of options and does good file format and data format inference.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('file.csv')\n",
    "```\n",
    "\n",
    "The input ('file.csv') can be any valid path, including URLs.\n",
    "\n",
    "You can read about all the options here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON (Javascript Object Notation) Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next file type we will look at is JSON. This is a popular format for transferring data over the web via APIs, and is also a plaintext file format.\n",
    "\n",
    "JSON is very similar to the text representation of a Python dictionary and lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "\"day\": \"Saturday\",\n",
      "\"week\": 3,\n",
      "\"isSunny\": true,\n",
      "\"goals\": [\"eat breakfast\", \"write a book\", \"eat lunch\"]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = \"\"\"\n",
    "{\n",
    "\"day\": \"Saturday\",\n",
    "\"week\": 3,\n",
    "\"isSunny\": true,\n",
    "\"goals\": [\"eat breakfast\", \"write a book\", \"eat lunch\"]\n",
    "}\n",
    "\"\"\"\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main downside with **hand-writing** JSON is that it is very picky about getting everything right. Even though it's very readable, it should not be considered human writable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python and Pandas work well with JSON files, as Python's json library offers buit-in support for them.\n",
    "Tabular data can be stored in JSON in a variety of ways, called \"orientations\".\n",
    "\n",
    "- **'split'** : dict like {'index' -> [index], 'columns' -> [columns], 'data' -> [values]}\n",
    "- **'records'** : list like [{column -> value}, ... , {column -> value}]\n",
    "- **'index'** : dict like {index -> {column -> value}}\n",
    "- **'columns'** : dict like {column -> {index -> value}}\n",
    "- **'values'** : just the values array\n",
    "- **'table'** : dict like {'schema': {schema}, 'data': {data}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the data from your DataFrame to a JSON file with **to_json()** function:\n",
    "\n",
    "```python\n",
    "df.to_json('data.json', orient='index')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also load the data from a JSON file with **read_json()**.\n",
    "\n",
    "```python\n",
    "df = pd.read_json('data.json', orient='index')\n",
    "```\n",
    "\n",
    "In this case, the *orient* parameter is very important because it specifies how Pandas understands the structure of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use the **json module** to load (read) and dump (write) JSON files.\n",
    "This module has 4 main functions:\n",
    "    \n",
    "| function | read/write | file/string |\n",
    "| :---:    | :----:     |  :-----:    |\n",
    "| load()   |  read      | file        |\n",
    "| dump()   |  write     | file        |\n",
    "| loads()  |  read      | string      |\n",
    "| dumps()  |  write     | string      |\n",
    "\n",
    "\n",
    "To read the data example we created above, which means converting from JSON to Python:\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "json.loads(data)\n",
    "```\n",
    "\n",
    "And to convert a Python object to JSON:\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "json.dumps(data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTML Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An HTML is a plaintext file that uses hypertext markup language to help browers render web pages. These files carry the extension *.html* and *htm*, and in order to work with them, you will need to install an HTML library like **lxml** or **html5lib**.\n",
    "\n",
    "Once you have these libraries, you can \n",
    "\n",
    "\n",
    "\n",
    "You can save your DataFrame as an HTML file with **to_html()**:\n",
    "\n",
    "```python\n",
    "df = pd.DataFrame(data=data).T\n",
    "df.to_html('data.html')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In binary files, there is no terminator for a line and the data is stored after converting it into machine understandable binary language. Unlike text files, binary files are not human readable, this means, if you try to open them in any text editor, it will either not open, or show the data in an unrecognizable format.\n",
    "\n",
    "Without documentation, proper software, and version management, these files can be difficult to work with.\n",
    "\n",
    "Below, we show you a very simple example of how you could read and write to a binary file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Writing to a Binary File\n",
    "\n",
    "Opening a file in binary format is very similar to opening a text file, just add **\"b\"** to the mode parameter. For example, **\"rb\"** mode opens the file in binary format for reading only.\n",
    "\n",
    "The following example stores a list of numbers in a binary file:\n",
    "\n",
    "```python\n",
    "f = open('binfile.bin', 'wb')\n",
    "num = [5, 10, 15, 20, 25]\n",
    "arr = bytearray(num)\n",
    "f.write(arr)\n",
    "f.close()\n",
    "```\n",
    "\n",
    "The function **bytearray** converts the list into a byte representation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read a binary file like the one shown above, the output of the **read()** function is turned back into a list:\n",
    "\n",
    "```python\n",
    "f = open('binfile.bin', 'wb')\n",
    "num = list(f.read())\n",
    "f.close()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are, of course, advantages to using binary file:\n",
    "\n",
    "- smaller file sizes\n",
    "- supports more features (compression, multiple dataset storage, self-description, etc)\n",
    "- quicker read/write times\n",
    "- entire ecosystems of supported software\n",
    "\n",
    "Due to this, the developers of Pandas have created a whole set of IO tools that allow not only to read/write text files, but also binary and even SQL file types.\n",
    "\n",
    "| format type | data | reader | writer |\n",
    "|    :---:    |:----:|:-----: | :---:  |\n",
    "| binary | MS Excel  | read_excel | to_excel |\n",
    "| binary | Python Pickle Format | read_pickle | to_pickle |\n",
    "| binary | HDF5 Format | read_hdf | to_hdf |\n",
    "| binary | SPSS | read_spss | |\n",
    "\n",
    "This table contains only a few examples but you can see all of the available IO tools here: https://pandas.pydata.org/pandas-docs/dev/user_guide/io.html\n",
    "\n",
    "In the next sections, we show you a few of these standards  for storing tabular data in binary formats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excel Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Microsoft Excel is probably the most widely-used spreadsheet software, and even though it is a binary file format, you can read and write Excel files in Pandas, similar to CSV files.\n",
    "\n",
    "An additional requirement however, depending on the Excel version you will work with, you will need to install other Python packages first.\n",
    "\n",
    "- **xlrd** to read Excel files *.xls* (Excel 2003)\n",
    "\n",
    "- **openpyxl** to read/write *.xlsx* files (Excel 2007+)\n",
    "\n",
    "- **pyxlsb** to read binary Excel *.xlsb*\n",
    "\n",
    "\n",
    "You can install them using **pip** with a single command:\n",
    "```python\n",
    "pip install xlrd openpyxl pyxlsb\n",
    "```\n",
    "\n",
    "Or using Conda:\n",
    "```python\n",
    "conda install xlrd openpyxl pyxlsb\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have installed the neccessary packages, you can read an Excel file with **read_excel()**:\n",
    "\n",
    "```python\n",
    "df = pd.read_excel('data.xlsx')\n",
    "```\n",
    "\n",
    "And save your DataFrame in an Excel file with **to_excel()**:\n",
    "```python\n",
    "df.to_excel('data2.xlsx')\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling is the act of converting Python objects into byte streams, and unpickling is the inverse process. This format makes it easy to store any Python objects as binary files and keep the data and hierarchy of the object.\n",
    "\n",
    "However, you should remember that they will only read back correctly if the Python version and package versions of the readers are the same as the writer.\n",
    "\n",
    "The pickle module has the same interface as the json module:\n",
    "\n",
    "| function | read/write | file/string |\n",
    "| :---:    | :----:     |  :-----:    |\n",
    "| load()   |  read      | file        |\n",
    "| dump()   |  write     | file        |\n",
    "| loads()  |  read      | string      |\n",
    "| dumps()  |  write     | string      |\n",
    "\n",
    "\n",
    "The following command pickles the DataFrame *df* and saves it as *data.pickle*:\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "with open('data.pickle', 'wb') as f:\n",
    "    pickle.dump(df, f)\n",
    "```    \n",
    "\n",
    "While, the following unpickles *data.pickle* and loads it as a pandas DataFrame:\n",
    "\n",
    "```python   \n",
    "with open('data.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the Pandas built-in functionality for dealing with pickle files.\n",
    "\n",
    "```python\n",
    "df.to_pickle('data.pickle')   # Pickles df and saves it as data.pickle\n",
    "\n",
    "pd.read_pickle('data.pickle')   # Unpickles and reads data.pickle\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As a word of caution, you should always beware of loading pickles from unstructured sources. When you unpickle an unstrustworthy file, it could execute arbitrary code on your machine, performing dangerous actions and exploiting your device.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 (Hierarchical Data Format 5) is a file format that has become quite popular. It can store a large amount of data in a single file, has compression features, and can store many datasets. HDF5 file format has a filesystem-like organization inside it, which means you can store the datasets in their own \"folder sctructure\" inside the file.\n",
    "\n",
    "HDFStore is dictionary-like object for reading and writing pandas using the **PyTables** library.\n",
    "\n",
    "To get data into an hdf5 file, you need to specify the filename and the key/group of the dataset. If you don't give it a path, it will put the key in the root group, which is the \"root folder\" of the hdf5 file. \n",
    "\n",
    "```python\n",
    "df.to_hdf('store.h5', key='/data', format='table', mode='a')\n",
    "```\n",
    "\n",
    "And in order to access and read from the HDF5 file:\n",
    "\n",
    "```python\n",
    "pd.read_hdf('store.h5', key='/data')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the **open()** method, **to_hdf()** takes the **mode** parameter (\"a\", \"w\" or \"r+\"). **to_hdf()** also requires a format parameter. You can read more about the different options here: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_hdf.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
