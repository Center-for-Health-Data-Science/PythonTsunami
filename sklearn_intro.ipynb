{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn (`sklearn`)\n",
    "\n",
    "- Henry Webel at [NNF CPR](https://www.cpr.ku.dk/staff/rasmussen-group/?pure=en/persons/662319)\n",
    "- Python Tsumanmi 2020 at [SUND](https://healthsciences.ku.dk/)\n",
    "- Session : `Day 2, 13:00 -17.00` (Track 2)\n",
    "  - Pre-requisites: Python Intro, NumPy, minimal Pandas, matplotlib\n",
    "  \n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pythontsunami/teaching/blob/sklearn/sklearn_intro.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Saving the notebook in Drive\n",
    "Save a copy in your drive if you want to save your changes: `File` -> `Save a copy in Drive`\n",
    "\n",
    "\n",
    "![Save Colab Notebook in Google Drive](figures/colab_save_in_drive.png)\n",
    "\n",
    "or \n",
    "\n",
    "![Save Colab Notebook in Google Drive](figures/colab_save_in_drive_2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Table of Contents in Colab**\n",
    "> Allows easier navigation\n",
    "\n",
    "![Table of content in Colab](figures/colab_toc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "1. Scikit-learn API introdoction.\n",
    "2. If needed: Machine Learning\n",
    "3. Use-Case with different objects from scikit-learn\n",
    "    - this includes some exercises\n",
    "4. Further material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn\n",
    "\n",
    "Library of algorithms for Data Science with unified interface.\n",
    "\n",
    "This notebook is based on the available [tutorials](https://scikit-learn.org/stable/tutorial/index.html) which are interesting to read, but unfortunately note based on executable notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "\n",
    "- [Glossary](https://scikit-learn.org/stable/glossary.html#glossary)\n",
    "- [examples](https://github.com/scikit-learn/scikit-learn/tree/master/examples)\n",
    "- [API design for machine learning software: experiences from the scikit-learn project](https://arxiv.org/abs/1309.0238)\n",
    "- [Géron, Aurélien (2019): Hands on Machine Learning ith Scikit-Learn, Keras and TensorFlow, Vol. 2, Ch. 1- 9](https://github.com/ageron/handson-ml2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn API main principles\n",
    "> Géron (2019): 64f. and [scikit-learn-paper](https://arxiv.org/abs/1309.0238)\n",
    "\n",
    "First some theory and names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consistency\n",
    "- `Estimators`: Interface for building and fitting models\n",
    "    - `fit` method returns fitted models\n",
    "    - supervised: `fit(X_train, y_train)`\n",
    "    - unsupervised: `fit(X_train)`\n",
    "    - factory to produce model objects\n",
    "- `Predictors(Estimator)`: Interface for making predictions\n",
    "    - `fit`, `predict` and `score`\n",
    "    - supervised and unsupervised: `predict(X_test)`\n",
    "    - performance assessment: `score` (the higher, the better)\n",
    "    - clustering: `fit_predict` exists\n",
    "    - extends `Estimator`\n",
    "- `Transformers(Estimator)`: Interface for converting data\n",
    "    - `fit`, `transform`, and `fit_transform`\n",
    "    - extends `Estimator`\n",
    "\n",
    "    \n",
    "> Transformer which is also a predictor? Where is the difference between transform and predict?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composition  \n",
    "- `Pipeline` objects from a sequence of `Transformers` and a optinally a final `Predictor`\n",
    "- `FeatureUnion` objects for a two or more `Pipeline`s in parallel, yielding concatenated outputs.\n",
    "\n",
    "#### Inspection\n",
    "- learned `features_` have a underscore suffix `_`\n",
    "\n",
    "#### Sensible defaults\n",
    " - get your first models running quickly\n",
    " - sensible defaults for construction of `Estimators`\n",
    "\n",
    "> Side Note: \"A _hyperparameter_ is a parameter of a learning algorithm (not of the model).   \n",
    "> As such, it is not affected by the learning algorithm itself;   \n",
    "> it must be set prior to training and remains constant during training.\" (Géron 2019: 29)  \n",
    "> Constructor parameters of scikit-learn objects are hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, IFrame, display\n",
    "\n",
    "display(IFrame(src='https://scikit-learn.org', width=1024, height=1024, metadata=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Guide\n",
    "\n",
    "Some part of the [User Guide](https://scikit-learn.org/stable/user_guide.html) will be discussed.\n",
    "\n",
    "> The User Guide is an overall reference which can be followed in different orders.\n",
    "\n",
    "- [Different Estimator](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "- [preprocessing data](https://scikit-learn.org/stable/data_transforms.html): `sklearn.impute`, `sklearn.preprocessing`\n",
    "- [model selection (incl. metrics)](https://scikit-learn.org/stable/model_selection.html): `sklearn.model_selection`\n",
    "- [Pipeline](https://scikit-learn.org/stable/data_transforms.html): `sklearn.pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some things to look at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.base\n",
    "# sklearn.base??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: CustomTransformer\n",
    "> scikit-learn is based on duck-typing, although we inherit some additional features for the interface from base classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin): \n",
    "    \"\"\"Don't use this. This is an example.\"\"\"\n",
    "    def __init__(self, my_bias=0): # no *args or **kargs\n",
    "        \"\"\"Add a bias/ intercept\"\"\"\n",
    "        self.my_bias = my_bias\n",
    "    def fit(self, X, y=None): \n",
    "        return self # nothing else to do\n",
    "    def transform(self, X):\n",
    "        return np.c_[X, np.array([self.my_bias] * len(X))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(range(10))\n",
    "custom_transformer = CustomTransformer(my_bias=10)\n",
    "custom_transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Scikit-learn uses the underlying numpy.arrays of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Tutorial\n",
    "\n",
    "1. Supervised\n",
    "    1. Regression\n",
    "    2. Classification\n",
    "2. Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adapt Machine Learning Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification vs Regression\n",
    "\n",
    "What is the difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study: Age-prediction\n",
    "> Thanks for [Sam Bradley](https://www.dtu.dk/english/service/phonebook/person?id=145074&cpid=266426&tab=0)\n",
    "telling me and [Denis Shepelin](https://www.dtu.dk/english/service/phonebook/person?id=126180&tab=2&qt=dtupublicationquery)\n",
    "telling him. There I stop the tracking:) \n",
    "\n",
    "A paper presenting age predictions based on RNA measurements did upload the data\n",
    "- [paper](https://www.sciencedirect.com/science/article/pii/S1872497317301643)\n",
    "- [data](https://zenodo.org/record/2545213/#.X43R0dAzb-g)\n",
    "\n",
    "> It's a set of features and labels\n",
    "> For first predictions you do not need to understand the biology,  \n",
    "> but to explain _odd_ things, more knowledge is most of the times helpful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feel free to re-implement your own paper of interest \n",
    "\n",
    "> If you are interested in a paper which you have the data for, go on and try to adapt the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_train_data = \"https://zenodo.org/record/2545213/files/train_rows.csv\"\n",
    "url_test_data = \"https://zenodo.org/record/2545213/files/test_rows_labels.csv\"\n",
    "\n",
    "# additional data not used for now\n",
    "url_train_normal = \"https://zenodo.org/record/2545213/files/training_data_normal.tsv\"\n",
    "url_test_data_wo_labels = \"https://zenodo.org/record/2545213/files/test_rows.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(url_train_data, sep='\\t')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_table(url_test_data)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_normal = pd.read_csv(url_train_normal, sep='\\t')\n",
    "# train_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_wo_label = pd.read_table(url_test_data) # tab seperated data is often tsv format\n",
    "# test_data_wo_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLUMN = 'Age'\n",
    "\n",
    "y_train = train_data[TARGET_COLUMN]\n",
    "y_test  = test_data[TARGET_COLUMN] # pop() if you want to modify test_data inplace\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test  = test_data.drop(TARGET_COLUMN, axis=1)\n",
    "X_train = train_data.drop(TARGET_COLUMN, axis=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = X_train  # from here it's easy to write a function display what you are interested in\n",
    "n_na = _df.isna().sum().sum()\n",
    "print(f\"Found # NAs: {n_na}\")\n",
    "if n_na:\n",
    "    row_with_nas = _df.isna().any(axis=1)\n",
    "    display(_df.loc[row_with_nas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = X_train.hist(figsize=(15,15), sharex=True, sharey=True)\n",
    "# _ = X_test.hist(figsize=(15,15), sharex=True, sharey=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg = lin_reg.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Factory is replaced by fitted model, but calling fit again first erases previously fitted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = lin_reg.predict(X_test)\n",
    "y_test_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lin_mse = mean_squared_error(y_true=y_test, y_pred=y_test_pred)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Replace the model and see if this improves your results.\n",
    "\n",
    "1. Select a different [model](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "2. Adapt only the first block from above below here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Model Selection\n",
    "\n",
    "1. On the combined data set, split the data into a balanced train and test data set of 80/20 (i.e. 80% of the data goes into the training data set). \n",
    "2. Perform cross-validation\n",
    "3. \n",
    "\n",
    "#### Hints\n",
    "- `from sklearn.model_selection import StratifiedShuffleSplit` and [model-selection tutorial](https://scikit-learn.org/stable/model_selection.html)\n",
    "\n",
    "> The aim is to get you started reading the documentation and understand the function signatures  \n",
    "> while you are able to ask as many questions as you like:)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([train_data, test_data])\n",
    "old_index = pd.Series(data.index)\n",
    "data.index = old_index.index\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(TARGET_COLUMN, axis=1)\n",
    "y = data[TARGET_COLUMN]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Check target variable\n",
    "\n",
    "1. Check if the distribution of `Age` is the same in the predefined test and train set (there are several possibilites to do that)\n",
    "2. How to stratify the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Custom `Transformer`\n",
    "\n",
    "Create a custom Transformer adding the squared $x=x^2$ of each feature to the training data.\n",
    "\n",
    "> scikit-learn is based on duck-typing, although we inherit some additional features for the interface from base classes.\n",
    "\n",
    "##### !!! Don't use this\n",
    "To add interaction effects, please use [`sklearn.preprocessing.PolynomialFeatures`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_moment=None):  # no *args or **kargs\n",
    "        self.add_moment = add_moment\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to fit\n",
    "\n",
    "    def transform(self, X):\n",
    "        # your code here\n",
    "        return X\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_moment=True)\n",
    "extendend_data = attr_adder.transform(X_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Can you think of a better transformations? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Simple pipeline\n",
    "\n",
    "Let's add a standardiser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler = StandardScaler(copy=True, with_mean=True, with_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you like, mask some data and add an imputer to the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_keep = np.random.random(size=X.shape) > 0.1\n",
    "X.where(mask_keep) # Now X has not changed yet. Assing to a new reference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Combining pipelines\n",
    "\n",
    "What if we would have an additional category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_attribs = \n",
    "# cat_attribs = \n",
    "\n",
    "# num_pipeline = Pipeline([\n",
    "#         ('selector', DataFrameSelector(num_attribs)),\n",
    "#         ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "#         ('attribs_adder', AttributesAdder()),\n",
    "#         ('std_scaler', StandardScaler()),\n",
    "#     ])\n",
    "\n",
    "# cat_pipeline = Pipeline([\n",
    "#         ('selector', DataFrameSelector(cat_attribs)),\n",
    "#         ('cat_encoder', OneHotEncoder(sparse=False)),\n",
    "#     ])\n",
    "\n",
    "# from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "# full_pipeline = FeatureUnion(transformer_list=[\n",
    "#         (\"num_pipeline\", num_pipeline),\n",
    "#         (\"cat_pipeline\", cat_pipeline),\n",
    "#     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "- meta-estimators `GridSearchCV` and `RandomizedSearchCV`\n",
    "- `best_estimator_` attribute\n",
    "\n",
    "- [Diabetes example](https://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "cross_validate(lin_reg, X, y=y, groups=y, cv=StratifiedKFold(5), scoring=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Replace `scoring=None` by other metrics by reading the documentation.\n",
    "- Extend this to several estimators and record the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning\n",
    "\n",
    "`GridSearchCV` and `RandomSearchCV` on model hyperparameters.\n",
    "\n",
    "> Side Note: \"A _hyperparameter_ is a parameter of a learning algorithm (not of the model).   \n",
    "> As such, it is not affected by the learning algorithm itself;   \n",
    "> it must be set prior to training and remains constant during training.\" (Géron 2019: 29)  \n",
    "> Constructor parameters of scikit-learn objects are hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Easy exercise: Image Classification \n",
    "\n",
    "Run [image-classification example](https://github.com/scikit-learn/scikit-learn/tree/master/examples/classification) and exchange the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended exercise: automated stratified Cross-Valdiation \n",
    "Goals:\n",
    "- Understanding documentation of [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) function\n",
    "- apply stratified KFold data splitting for imbalanced data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Stratified Splitting is default for [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLDER_THAN = 60\n",
    "print(f\"Binary (Dummy) Variable assigning 1 if some is older than {OLDER_THAN} years old.\")\n",
    "y_binary = (y > OLDER_THAN).astype(int)\n",
    "y_binary.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will result in a imbalanced classification problem, where the aim is to predict if someone is older than `OLDER_THAN`."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "ald_study",
   "language": "python",
   "name": "ald_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
